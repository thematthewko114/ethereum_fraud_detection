{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd28465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timezone \n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0407474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your list of packages you've installed in conda.\n",
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d84f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset from Kaggle\n",
    "df = pd.read_csv('dataset_71k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c007484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize dataset properties\n",
    "print(\"Dataset properties before processing:\")\n",
    "print(\"Entries:\", len(df))\n",
    "print(\"Columns:\", len(df.columns))\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Include columns:\", list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e89dc45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_json('txn_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c29bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv(\"blockscout_txn_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd546940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the dataset\n",
    "# run here if txn and addr data are present\n",
    "txn_df = pd.read_csv('blockscout_txn_output.csv')\n",
    "merged_df = df.merge(txn_df, on='hash')\n",
    "merged_df.to_csv(\"merged_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18568e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['from_address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7087c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_json('addr_data.json')\n",
    "data_df.to_csv(\"blockscout_addr_output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae83238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "addr_df = pd.read_csv('blockscout_addr_output.csv')\n",
    "addr_df['hash'] = addr_df['hash'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cafc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_1 = merged_df.merge(addr_df, how='left', left_on='from_address', right_on='hash')\n",
    "merged_df_2 = merged_df_1.merge(addr_df, how='left', left_on='to_address', right_on='hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422a7dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_2.to_csv(\"merged_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3563f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "data_df = None\n",
    "txn_df = None\n",
    "merged_df = None\n",
    "merged_df_1 = None\n",
    "merged_df_2 = None\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"merged_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97947851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_json_column(df_arg, column_name):\n",
    "    df_arg[column_name] = df_arg[column_name].str.replace(\"'\", '\"')\n",
    "    # Parse the JSON column into a dictionary\n",
    "    df_arg[column_name] = df_arg[column_name].apply(json.loads)\n",
    "\n",
    "    # Get unique keys from the expanded JSON data\n",
    "    unique_keys = set()\n",
    "    for row in df_arg[column_name]:\n",
    "        unique_keys.update(row.keys())\n",
    "\n",
    "    # Create new columns for each unique key\n",
    "    for key in unique_keys:\n",
    "        df_arg[column_name+'_'+key] = df_arg[column_name].apply(lambda x: x.get(key))\n",
    "\n",
    "    return df_arg\n",
    "\n",
    "df = expand_json_column(df, 'fee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_values(row):\n",
    "    values = eval(row)  # Evaluate the string as a Python expression\n",
    "    return values[0], values[1]\n",
    "\n",
    "df[['confirmation_duration_0', 'confirmation_duration_1']] = df['confirmation_duration'].apply(lambda row: pd.Series(extract_values(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da947b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change existing column\n",
    "\n",
    "def calculate_elapsed_time(row):\n",
    "    elapsed_time = pd.Timestamp.utcnow() - row['timestamp_obj']\n",
    "    return elapsed_time\n",
    "\n",
    "df['is_scam'] = df.apply(lambda row: 1 if row['from_scam'] == 1 or row['to_scam'] == 1 else 0, axis=1)\n",
    "df['timestamp_obj'] = pd.to_datetime(df['block_timestamp'])\n",
    "df['elapsed_time'] = df.apply(lambda row: calculate_elapsed_time(row), axis=1)\n",
    "df['tx_token_transfer'] = df.apply(lambda row: 'token_transfer' in row['tx_types'], axis=1)\n",
    "df['tx_coin_transfer'] = df.apply(lambda row: 'coin_transfer' in row['tx_types'], axis=1)\n",
    "df['tx_contract_call'] = df.apply(lambda row: 'contract_call' in row['tx_types'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c593123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column names and replace duplicated columns to avoid confusion after merging\n",
    "df.drop(columns=['hash', 'hash_y', 'nonce_y', 'position', \n",
    "                'value_y', \n",
    "                'gas_limit', \n",
    "                'gas_price_y', \n",
    "                'raw_input', \n",
    "                'gas_used', \n",
    "                'block', \n",
    "                'timestamp',\n",
    "                'from_category',\n",
    "                'to_category',\n",
    "                'status',\n",
    "                'method',\n",
    "                'type',\n",
    "                'priority_fee',\n",
    "                'base_fee_per_gas',\n",
    "                'token_transfers',\n",
    "                'created_contract',\n",
    "                'has_error_in_internal_txs',\n",
    "                'actions',\n",
    "                'decoded_input',\n",
    "                'max_priority_fee_per_gas',\n",
    "                'revert_reason',\n",
    "                'tx_tag',\n",
    "                'creation_tx_hash_x',\n",
    "                'creator_address_hash_x',\n",
    "                'has_custom_methods_read_x',\n",
    "                'has_custom_methods_write_x',\n",
    "                'has_decompiled_code_x',\n",
    "                'has_logs_x',\n",
    "                'has_methods_read_x',\n",
    "                'has_methods_read_proxy_x',\n",
    "                'has_methods_write_x',\n",
    "                'has_methods_write_proxy_x',\n",
    "                'implementation_address_x',\n",
    "                'implementation_name_x',\n",
    "                'is_contract_x',\n",
    "                'is_verified_x',\n",
    "                'name_x',\n",
    "                'private_tags_x',\n",
    "                'public_tags_x',\n",
    "                'token_x',\n",
    "                'watchlist_address_id_x',\n",
    "                'watchlist_names_x',\n",
    "                'creation_tx_hash_y',\n",
    "                'creator_address_hash_y',\n",
    "                'has_custom_methods_read_y',\n",
    "                'has_custom_methods_write_y',\n",
    "                'has_decompiled_code_y',\n",
    "                'has_logs_y',\n",
    "                'has_methods_read_y',\n",
    "                'has_methods_read_proxy_y',\n",
    "                'has_methods_write_y',\n",
    "                'has_methods_write_proxy_y',\n",
    "                'implementation_address_y', \n",
    "                'implementation_name_y', \n",
    "                'is_contract_y', \n",
    "                'is_verified_y', \n",
    "                'name_y',\n",
    "                'private_tags_y', \n",
    "                'public_tags_y',\n",
    "                'token_y', \n",
    "                'watchlist_address_id_y', \n",
    "                'watchlist_names_y',\n",
    "                'from',\n",
    "                'to',\n",
    "                'tx_burnt_fee',\n",
    "                'max_fee_per_gas',\n",
    "                'result',\n",
    "                'fee_type',\n",
    "                'confirmation_duration',\n",
    "                'fee',\n",
    "                 'timestamp_obj',\n",
    "                 'from_scam',\n",
    "                 'to_scam',\n",
    "                 'tx_types',\n",
    "                 'block_timestamp'\n",
    "                ], inplace=True)\n",
    "df.rename(columns={\n",
    "    'hash_x': 'hash',\n",
    "    'nonce_x': 'nonce',\n",
    "    'value_x': 'value',\n",
    "    'gas_price_x': 'gas_price_txn',\n",
    "    'block_number_balance_updated_at_x': 'block_number_balance_updated_at_from',\n",
    "    'block_number_balance_updated_at_y': 'block_number_balance_updated_at_to',\n",
    "    'coin_balance_x': 'coin_balance_from',\n",
    "    'coin_balance_y': 'coin_balance_to',\n",
    "    'exchange_rate': 'exchange_rate_to',\n",
    "    'exchange_rate_y': 'exchange_rate_from',\n",
    "    'exchange_rate_x': 'exchange_rate_txn',\n",
    "    'has_beacon_chain_withdrawals_x': 'has_beacon_chain_withdrawals_from',\n",
    "    'has_token_transfers_x': 'has_token_transfers_from',\n",
    "    'has_tokens_x': 'has_tokens_from',\n",
    "    'has_validated_blocks_x': 'has_validated_blocks_from',\n",
    "    'has_beacon_chain_withdrawals_y': 'has_beacon_chain_withdrawals_to',\n",
    "    'has_token_transfers_y': 'has_token_transfers_to',\n",
    "    'has_tokens_y': 'has_tokens_to',\n",
    "    'has_validated_blocks_y': 'has_validated_blocks_to',\n",
    "}, inplace=True)\n",
    "df.to_csv(\"20231031_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa2c6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]['elapsed_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47305ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    \"Labels\": [\"Scam\", 'Not Scam'],\n",
    "    \"Is Scam\": [df['is_scam'].value_counts()[1], df['is_scam'].value_counts()[0]]\n",
    "})\n",
    "\n",
    "scam_count = 0\n",
    "non_scam_count = 0\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i]['is_scam'] == 1:\n",
    "        scam_count = scam_count + 1\n",
    "    else:\n",
    "        non_scam_count = non_scam_count + 1\n",
    "df1.plot.pie(y=\"Is Scam\")\n",
    "print(\"No. of rows that are not scam:\", scam_count)\n",
    "print(\"No. of rows that are scams:\", non_scam_count)\n",
    "print(\"Percentage of scam:\", format(scam_count/(scam_count+non_scam_count)*100, \".2f\"), \"%\")\n",
    "print(\"Percentage of non scam:\", format(non_scam_count/(scam_count+non_scam_count)*100, \".2f\"), \"%\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1bee7c7e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1384786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
